#!/bin/bash
#SBATCH --job-name=flow_tc
#SBATCH --gres=gpu:1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=8


eval "$(conda shell.bash hook)"
source scripts/wandb_api_key.sh
module load cuda/11.8
conda activate flowmm
source scripts/absolute_path.sh
export HYDRA_FULL_ERROR="1"

ROOT="${ABS_PATH%/}"
export WABDB_DIR="${ROOT}/job_runs/flowmm_benchmark_jarvis/outputs/wandb_outputs"
export FLOWMM_RUN_ROOT="${ROOT}/job_runs/flowmm_benchmark_jarvis/outputs"

ckpt="$(find "${FLOWMM_RUN_ROOT}" -type f -path '*/checkpoints/*.ckpt' 2>/dev/null | xargs -r ls -1 -t 2>/dev/null | head -n1)"
if [[ -z "${ckpt}" ]]; then
  echo "ERROR: No checkpoint found under ${FLOWMM_RUN_ROOT}"
  exit 1
fi
ckpt_dir="$(dirname "${ckpt}")"
subdir="${ckpt_dir}/inferences"
mkdir -p "${subdir}"

export PATH_TO_CHECKPOINT="${ckpt}"
export NAME_OF_SUBDIRECTORY_AT_CHECKPOINT="${subdir}"
export SLOPE_OF_INFERENCE_ANTI_ANNEALING="2.0"

ckpt="$PATH_TO_CHECKPOINT"
subdir="$NAME_OF_SUBDIRECTORY_AT_CHECKPOINT"
slope="$SLOPE_OF_INFERENCE_ANTI_ANNEALING"

# commands
nvidia-smi
bash "${ROOT}/models/flowmm/create_env_file.sh"

python "${ROOT}/models/flowmm/scripts_model/evaluate.py" reconstruct \
  "${ckpt}" --subdir "${subdir}" --inference_anneal_slope "${slope}" --stage test --single_gpu && \
python "${ROOT}/models/flowmm/scripts_model/evaluate.py" consolidate \
  "${ckpt}" --subdir "${subdir}"

echo "Done"

